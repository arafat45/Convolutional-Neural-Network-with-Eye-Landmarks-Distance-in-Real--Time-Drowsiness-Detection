import cv2
import dlib
import numpy as np
from keras.models import load_model
from scipy.spatial import distance as dist
from imutils import face_utils
from keras import backend as K
K.set_image_dim_ordering('th')
import time

frm = [0]
prd = [0]
k = 0
i = 0
j=  0
e = [0] 
f= [0]  
g= [0] 
jt = 0
r = 0
w=0
blinks = 0
diff = 0 
duration = 0
dr = 0
no_fr = 1
ear = 0.6

num_channel=1
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')
(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"]
(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"]
def eye_aspect_ratio(eye):
	
	A = dist.euclidean(eye[1], eye[5])
	B = dist.euclidean(eye[2], eye[4])
	C = dist.euclidean(eye[0], eye[3])
	ear = (A + B) / (C)

	# return the eye aspect ratio
	return ear

# detect the face rectangle 
def detect(img, cascade = face_cascade , minimumFeatureSize=(20, 20)):
    if cascade.empty():
        raise (Exception("There was a problem loading your Haar Cascade xml file."))
    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=1, minSize=minimumFeatureSize)
    
    # if it doesn't return rectangle return array
    # with zero lenght
    if len(rects) == 0:
        return []

    #  convert last coord from (width,height) to (maxX, maxY)
    rects[:, 2:] += rects[:, :2]

    return rects

def cropEyes(frame):
	  
#	gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	gray = frame
	# detect the face at grayscale image
	te = detect(gray, minimumFeatureSize=(80, 80))

	# if the face detector doesn't detect face
	# return None, else if detects more than one faces
	# keep the bigger and if it is only one keep one dim
	if len(te) == 0:
		return None
	elif len(te) > 1:
		face = te[0]
	elif len(te) == 1:
		[face] = te

	# keep the face region from the whole frame
	face_rect = dlib.rectangle(left = int(face[0]), top = int(face[1]),
								right = int(face[2]), bottom = int(face[3]))
	
	# determine the facial landmarks for the face region
	shape = predictor(gray, face_rect)
	shape = face_utils.shape_to_np(shape)

	#  grab the indexes of the facial landmarks for the left and
	#  right eye, respectively
	(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"]
	(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"]

	# extract the left and right eye coordinates
	leftEye = shape[lStart:lEnd]
	rightEye = shape[rStart:rEnd]

	# keep the upper and the lower limit of the eye 
	# and compute the height 
	l_uppery = min(leftEye[1:3,1])
	l_lowy = max(leftEye[4:,1])
	l_dify = abs(l_uppery - l_lowy)

	# compute the width of the eye
	lw = (leftEye[3][0] - leftEye[0][0])

	# we want the image for the cnn to be (26,34)
	# so we add the half of the difference at x and y
	# axis from the width at height respectively left-right
	# and up-down 
	minxl = (leftEye[0][0] - ((34-lw)/2))
	maxxl = (leftEye[3][0] + ((34-lw)/2)) 
	minyl = (l_uppery - ((26-l_dify)/2))
	maxyl = (l_lowy + ((26-l_dify)/2))
	
	# crop the eye rectangle from the frame
	left_eye_rect = np.rint([minxl, minyl, maxxl, maxyl])
	left_eye_rect = left_eye_rect.astype(int)
	left_eye_image = gray[(left_eye_rect[1]):left_eye_rect[3], (left_eye_rect[0]):left_eye_rect[2]]
	
	# same as left eye at right eye
	r_uppery = min(rightEye[1:3,1])
	r_lowy = max(rightEye[4:,1])
	r_dify = abs(r_uppery - r_lowy)
	rw = (rightEye[3][0] - rightEye[0][0])
	minxr = (rightEye[0][0]-((34-rw)/2))
	maxxr = (rightEye[3][0] + ((34-rw)/2))
	minyr = (r_uppery - ((26-r_dify)/2))
	maxyr = (r_lowy + ((26-r_dify)/2))
	right_eye_rect = np.rint([minxr, minyr, maxxr, maxyr])
	right_eye_rect = right_eye_rect.astype(int)
	right_eye_image = gray[right_eye_rect[1]:right_eye_rect[3], right_eye_rect[0]:right_eye_rect[2]]

	# if it doesn't detect left or right eye return None
	if 0 in left_eye_image.shape or 0 in right_eye_image.shape:
		return None
	# resize for the conv net
	left_eye_image = cv2.resize(left_eye_image, (34, 26))
	right_eye_image = cv2.resize(right_eye_image, (34, 26))
	right_eye_image = cv2.flip(right_eye_image, 1)
	# return left and right eye
	return left_eye_image, right_eye_image 

# make the image to have the same format as at training 
def cnnPreprocess(img):
    test_image=cv2.resize(img,(24,24))
    test_image = np.array(test_image)
    test_image = test_image.astype('float32')
    test_image /= 255
    
    if num_channel==1:
    	if K.image_dim_ordering()=='th':
    		test_image= np.expand_dims(test_image, axis=0)
    		test_image= np.expand_dims(test_image, axis=0)
    
    	else:
    		test_image= np.expand_dims(test_image, axis=3) 
    		test_image= np.expand_dims(test_image, axis=0)
    
    else:
    	if K.image_dim_ordering()=='th':
    		test_image=np.rollaxis(test_image,2,0)
    		test_image= np.expand_dims(test_image, axis=0)
    
    	else:
    		test_image= np.expand_dims(test_image, axis=0)
    
    return test_image

def main():
	# open the camera,load the cnn model
   a = time.time() 
   global k,i,j,e,f,g,diff,prd,r,w,p,alpha,blinks,jt,duration,dr,no_fr,ear
   camera = cv2.VideoCapture('lwg_sample2.mp4')
   model = load_model('8th_attempt.h5')
	
	# blinks is the number of total blinks ,close_counter
	# the counter for consecutive close predictions
	# and mem_counter the counter of the previous loop 
   close_counter = blinks = mem_counter= 0
   state = ''
   while True:
		 
      ret, frame = camera.read()
      print(np.size(frame))
      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
		
		# detect eyes
      eyes = cropEyes(gray)
      if eyes is None:
          continue
      else:
          left_eye,right_eye = eyes
		
		# average the predictions of the two eyes 
      prediction = (model.predict_classes(cnnPreprocess(left_eye)) + model.predict_classes(cnnPreprocess(right_eye)))/2.0
		
      if prediction == 0.5:
          prediction = 0
    
      if prediction > 0.5 :
          r += 1
          if r == 1:
              e.append(w)
              prd.append(0)
              continue
      # blinks
		# if the eyes are open reset the counter for close eyes
      if prediction < 0.5 :
         r = 0
         state = 'open'
         alpha  = 0
         close_counter = 0
      else:
         state = 'close'
         alpha = 1
         close_counter += 1
		
		# if the eyes are open and previousle were closed
		# for sufficient number of frames then increcement 
		# the total blinks

		# if the eyes are open and previousle were closed
		# for sufficient number of frames then increcement 
		# the total blinks


		# draw the total number of blinks on the frame along with
		# the state for the frame

      cv2.putText(frame, "CNN predicated State: {}".format(state), (0, 50),
			cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

      prediction = prediction 
      prd.append(prediction)
      k += 1
      frm.append(k)
      
      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
#    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
#    for (x,y,w,h) in faces:
#        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)
#        eyes = eye_cascade.detectMultiScale(gray, 1.3, 5)
#        for (ex,ey,ew,eh) in eyes:
#            frame = cv2.rectangle(frame,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)

      rects = detector(gray, 1)
        
      for rect in rects:
    
                shape = predictor(gray, rect)
                shape = face_utils.shape_to_np(shape)
                
                leftEye = shape[lStart:lEnd]
                rightEye = shape[rStart:rEnd]
                leftEAR = eye_aspect_ratio(leftEye)
                rightEAR = eye_aspect_ratio(rightEye)
                
                ear = (leftEAR + rightEAR) / 2.0
                
                leftEyeHull = cv2.convexHull(leftEye)
                rightEyeHull = cv2.convexHull(rightEye)
                cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)
                cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)
                
                cv2.putText(frame, "eye landmarks distance:{:.2f}".format(ear), (0, 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

    
                e.append(ear)
                w = ear
    

      
      if ear <= 0.45:
        p = 1
        alpha = 1
      else:
        p = 0
        alpha  = 0
        
#      alpha = prediction and p      
      
      b = time.time()
      diff = b - a
      
      print("processing time per frame: " , diff , "s")
      
      if alpha > 0.5:
          
          duration = duration + diff
          
      else:
          
          duration = 0;

      # blinks
		# if the eyes are open reset the counter for close eyes
      if jt == 0: 
        if alpha > 0.5:
          blinks = blinks+1
          no_fr = no_fr+1
          jt = 1
        else:
          jt = 0
      else:
          if alpha < 0.5:
              jt = 0
      d = duration/1000;
      cv2.putText(frame, "Alpha: {}".format(alpha), (0, 80),
			cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
      
      cv2.putText(frame, "Blinks: {}".format(blinks), (0, 110),
			cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

      cv2.putText(frame, "Blinking time: {:.2f}".format(d), (0, 140),
			cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
      f.append(diff)
      j = j + diff
      g.append(j)
      dr = dr+d
      cv2.putText(frame, "Avg Blinking time: {:.2f}".format(dr/no_fr), (0, 170),
			cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
		# show the frame
      cv2.imshow('blinks counter', frame)
      print(dr/no_fr)
      key = cv2.waitKey(1) & 0xFF
      
      

		# if the `q` key was pressed, break from the loop
      if key == ord('q'):
          break
	# do a little clean up
   cv2.destroyAllWindows()
   del(camera)
   print(blinks)


if __name__ == '__main__':
	main()
