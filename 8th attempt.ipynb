{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/data2'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=24\n",
    "img_cols=24\n",
    "num_channel=1\n",
    "num_epoch=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "img_data_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-close eye\n",
      "\n",
      "Loaded the images of dataset-open eye\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\tfor img in img_list:\n",
    "\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\t\tinput_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\t\tinput_img_resize=cv2.resize(input_img,(24,24))\n",
    "\t\timg_data_list.append(input_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "if num_channel==1:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data= np.expand_dims(img_data, axis=1) \n",
    "\t\tprint (img_data.shape)\n",
    "\telse:\n",
    "\t\timg_data= np.expand_dims(img_data, axis=4) \n",
    "\t\tprint (img_data.shape)\n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_dim_ordering()=='th':\n",
    "\t\timg_data=np.rollaxis(img_data,3,1)\n",
    "\t\tprint (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:5000]=1\n",
    "labels[5000:10000]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['close eye','open eye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=img_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(1, 24, 24..., padding=\"same\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  \n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(128, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(64, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "model.compile(loss='binary_crossentropy',optimizer= adam(lr=0.001),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/150\n",
      "  64/8000 [..............................] - ETA: 24s - loss: 0.0421 - acc: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 29s 4ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0045 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.99850, saving model to weights.best.hdf5\n",
      "Epoch 2/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0179 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.99850\n",
      "Epoch 3/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0065 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.99850 to 0.99900, saving model to weights.best.hdf5\n",
      "Epoch 4/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 5.0326e-04 - acc: 0.9999 - val_loss: 0.0061 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99900\n",
      "Epoch 5/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.0052 - acc: 0.9979 - val_loss: 0.0138 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99900\n",
      "Epoch 6/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0101 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99900\n",
      "Epoch 7/150\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 1.5411e-04 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99900\n",
      "Epoch 8/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0156 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99900\n",
      "Epoch 9/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99900\n",
      "Epoch 10/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 0.0073 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99900\n",
      "Epoch 11/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99900\n",
      "Epoch 12/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 8.0747e-04 - acc: 0.9998 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99900\n",
      "Epoch 13/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0068 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99900\n",
      "Epoch 14/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0131 - val_acc: 0.9965\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99900\n",
      "Epoch 15/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.0087 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99900\n",
      "Epoch 16/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0011 - acc: 0.9994 - val_loss: 0.0083 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99900\n",
      "Epoch 17/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99900\n",
      "Epoch 18/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0060 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99900\n",
      "Epoch 19/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0065 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.99900\n",
      "Epoch 20/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0065 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99900\n",
      "Epoch 21/150\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0047 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99900\n",
      "Epoch 22/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 4.0681e-04 - acc: 0.9999 - val_loss: 0.0117 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99900\n",
      "Epoch 23/150\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99900\n",
      "Epoch 24/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.0052 - acc: 0.9980 - val_loss: 0.0154 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99900\n",
      "Epoch 25/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 5.3190e-04 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99900\n",
      "Epoch 26/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0147 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.99900\n",
      "Epoch 27/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0055 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.99900\n",
      "Epoch 28/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 7.5592e-04 - acc: 0.9998 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99900\n",
      "Epoch 29/150\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0060 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99900\n",
      "Epoch 30/150\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0058 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99900\n",
      "Epoch 31/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0058 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99900\n",
      "Epoch 32/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 6.2707e-04 - acc: 0.9998 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99900\n",
      "Epoch 33/150\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 6.5892e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99900\n",
      "Epoch 34/150\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 2.2299e-04 - acc: 0.9999 - val_loss: 0.0401 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99900\n",
      "Epoch 35/150\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99900\n",
      "Epoch 36/150\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 1.8915e-04 - acc: 0.9999 - val_loss: 0.0046 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.99900\n",
      "Epoch 37/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 5.1395e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99900\n",
      "Epoch 38/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 3.0497e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99900\n",
      "Epoch 39/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 4.0268e-05 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99900\n",
      "Epoch 40/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0294 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99900\n",
      "Epoch 41/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0066 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99900\n",
      "Epoch 42/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 1.2357e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.99900\n",
      "Epoch 43/150\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 7.2147e-05 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99900\n",
      "Epoch 44/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0066 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.99900\n",
      "Epoch 45/150\n",
      "8000/8000 [==============================] - 39s 5ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0056 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.99900 to 0.99950, saving model to weights.best.hdf5\n",
      "Epoch 46/150\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 6.3412e-04 - acc: 0.9998 - val_loss: 0.0071 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99950\n",
      "Epoch 47/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0036 - acc: 0.9994 - val_loss: 0.0017 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99950\n",
      "Epoch 48/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 6.9371e-04 - acc: 0.9997 - val_loss: 0.0022 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.99950\n",
      "Epoch 49/150\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0020 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99950\n",
      "Epoch 50/150\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 8.1938e-04 - acc: 0.9996 - val_loss: 0.0022 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99950\n",
      "Epoch 51/150\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 1.5378e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.99950\n",
      "Epoch 52/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0072 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.99950\n",
      "Epoch 53/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0015 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.99950\n",
      "Epoch 54/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 9.7177e-04 - acc: 0.9995 - val_loss: 0.0050 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.99950\n",
      "Epoch 55/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0033 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.99950\n",
      "Epoch 56/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0046 - acc: 0.9989 - val_loss: 0.0061 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.99950\n",
      "Epoch 57/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0037 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.99950\n",
      "Epoch 58/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 3.8966e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.99950\n",
      "Epoch 59/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 9.9979e-06 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.99950\n",
      "Epoch 60/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0063 - acc: 0.9976 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.99950\n",
      "Epoch 61/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 6.8157e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.99950\n",
      "Epoch 62/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 2.7859e-04 - acc: 0.9999 - val_loss: 0.0070 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.99950\n",
      "Epoch 63/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 2.4183e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.99950\n",
      "Epoch 64/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 1.1932e-05 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.99950\n",
      "Epoch 65/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 1.3095e-05 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.99950\n",
      "Epoch 66/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 2.2480e-06 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.99950\n",
      "Epoch 67/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 3.2876e-06 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.99950\n",
      "Epoch 68/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 3.3294e-06 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.99950\n",
      "Epoch 69/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 3.4182e-06 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.99950\n",
      "Epoch 70/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0064 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.99950\n",
      "Epoch 71/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 8.6417e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.99950\n",
      "Epoch 72/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0063 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.99950\n",
      "Epoch 73/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 2.3615e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.99950\n",
      "Epoch 74/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0023 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.99950\n",
      "Epoch 75/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 9.3540e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.99950\n",
      "Epoch 76/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 2.3554e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.99950\n",
      "Epoch 77/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 3.7613e-04 - acc: 0.9998 - val_loss: 0.0130 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.99950\n",
      "Epoch 78/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 7.0098e-04 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.99950\n",
      "Epoch 79/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 2.3678e-04 - acc: 0.9998 - val_loss: 0.0031 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.99950\n",
      "Epoch 80/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0014 - acc: 0.9994 - val_loss: 0.0095 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.99950\n",
      "Epoch 81/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0019 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.99950\n",
      "Epoch 82/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0038 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.99950\n",
      "Epoch 83/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 1.4323e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.99950\n",
      "Epoch 84/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0050 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.99950\n",
      "Epoch 85/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0039 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.99950\n",
      "Epoch 86/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0064 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.99950\n",
      "Epoch 87/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 32s 4ms/step - loss: 7.9537e-04 - acc: 0.9997 - val_loss: 0.0032 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.99950\n",
      "Epoch 88/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0018 - acc: 0.9991 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.99950\n",
      "Epoch 89/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 6.6878e-04 - acc: 0.9996 - val_loss: 0.0061 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.99950\n",
      "Epoch 90/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 3.1019e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.99950\n",
      "Epoch 91/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 3.2080e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.99950\n",
      "Epoch 92/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 1.7357e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.99950\n",
      "Epoch 93/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0688 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.99950\n",
      "Epoch 94/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0059 - acc: 0.9976 - val_loss: 0.0088 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.99950\n",
      "Epoch 95/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 6.7830e-04 - acc: 0.9998 - val_loss: 0.0057 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.99950\n",
      "Epoch 96/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 9.3690e-04 - acc: 0.9995 - val_loss: 0.0053 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.99950\n",
      "Epoch 97/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0023 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.99950\n",
      "Epoch 98/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 2.6052e-04 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.99950\n",
      "Epoch 99/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0012 - acc: 0.9994 - val_loss: 0.0041 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.99950\n",
      "Epoch 100/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0361 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.99950\n",
      "Epoch 101/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0017 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.99950\n",
      "Epoch 102/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 6.5717e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.99950\n",
      "Epoch 103/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 1.8258e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.99950\n",
      "Epoch 104/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 9.9835e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.99950\n",
      "Epoch 105/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 6.0281e-06 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.99950\n",
      "Epoch 106/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 5.7815e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.99950\n",
      "Epoch 107/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 4.5747e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.99950\n",
      "Epoch 108/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 2.4447e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.99950\n",
      "Epoch 109/150\n",
      "8000/8000 [==============================] - 2647s 331ms/step - loss: 1.5682e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.99950\n",
      "Epoch 110/150\n",
      "8000/8000 [==============================] - 28s 4ms/step - loss: 1.0462e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.99950\n",
      "Epoch 111/150\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 5.2283e-07 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.99950\n",
      "Epoch 112/150\n",
      "8000/8000 [==============================] - 28s 3ms/step - loss: 6.8288e-07 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.99950\n",
      "Epoch 113/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0058 - acc: 0.9989 - val_loss: 0.0013 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.99950\n",
      "Epoch 114/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 2.6155e-04 - acc: 0.9999 - val_loss: 0.0388 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.99950\n",
      "Epoch 115/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0038 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.99950\n",
      "Epoch 116/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 6.0462e-04 - acc: 0.9998 - val_loss: 0.0031 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.99950\n",
      "Epoch 117/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 2.5077e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.99950\n",
      "Epoch 118/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 7.7612e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.99950\n",
      "Epoch 119/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 1.6565e-04 - acc: 0.9999 - val_loss: 3.5723e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.99950 to 1.00000, saving model to weights.best.hdf5\n",
      "Epoch 120/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 1.8392e-05 - acc: 1.0000 - val_loss: 1.7437e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 1.00000\n",
      "Epoch 121/150\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 4.2929e-06 - acc: 1.0000 - val_loss: 3.1466e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 1.00000\n",
      "Epoch 122/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 2.3666e-06 - acc: 1.0000 - val_loss: 1.5321e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 1.00000\n",
      "Epoch 123/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 1.2349e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 1.00000\n",
      "Epoch 124/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0070 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 1.00000\n",
      "Epoch 125/150\n",
      "8000/8000 [==============================] - 29s 4ms/step - loss: 3.3725e-05 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 1.00000\n",
      "Epoch 126/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0071 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 1.00000\n",
      "Epoch 127/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0081 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 1.00000\n",
      "Epoch 128/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 1.0418e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 1.00000\n",
      "Epoch 129/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 5.3402e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00129: val_acc did not improve from 1.00000\n",
      "Epoch 130/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.0029 - acc: 0.9988 - val_loss: 0.0123 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 1.00000\n",
      "Epoch 131/150\n",
      "8000/8000 [==============================] - 30s 4ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0070 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 1.00000\n",
      "Epoch 132/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 4.3768e-04 - acc: 0.9998 - val_loss: 0.0098 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 1.00000\n",
      "Epoch 133/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 6.4606e-04 - acc: 0.9999 - val_loss: 0.0105 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 1.00000\n",
      "Epoch 134/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0083 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 1.00000\n",
      "Epoch 135/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 2.5313e-04 - acc: 0.9999 - val_loss: 0.0077 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 1.00000\n",
      "Epoch 136/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 7.3074e-04 - acc: 0.9996 - val_loss: 0.0090 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 1.00000\n",
      "Epoch 137/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 5.7027e-05 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 1.00000\n",
      "Epoch 138/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 5.9925e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 1.00000\n",
      "Epoch 139/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 7.6151e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 1.00000\n",
      "Epoch 140/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 1.2260e-06 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 1.00000\n",
      "Epoch 141/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 2.7184e-06 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 1.00000\n",
      "Epoch 142/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 7.3934e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 1.00000\n",
      "Epoch 143/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 1.4932e-06 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 1.00000\n",
      "Epoch 144/150\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 1.3489e-06 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 1.00000\n",
      "Epoch 145/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0159 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 1.00000\n",
      "Epoch 146/150\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0014 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 1.00000\n",
      "Epoch 147/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 2.5506e-04 - acc: 0.9999 - val_loss: 0.0056 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 1.00000\n",
      "Epoch 148/150\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 8.8421e-04 - acc: 0.9995 - val_loss: 0.0034 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 1.00000\n",
      "Epoch 149/150\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 1.3513e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 1.00000\n",
      "Epoch 150/150\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 3.3496e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 1.00000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=16, nb_epoch=num_epoch, callbacks=callbacks_list, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAGHCAYAAADGJeoHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XlcVOX+B/DPgCAurC4gpmaQIqmoqKDllhhg5pKaIrnccrn9LEk0EvVa3q4LmqZJKWlmYiamFmkpauHNDSwXrIRuECYKoyS7MoLA74+5zmUEYQbm8RzOfN6vl6+Xc+bMM18+Lnx55jnPUcXHx1eAiIiIzIqF1AUQERHRw8cGgIiIyAyxASAiIjJDbACIiIjMEBsAIiIiM8QGgIiIyAyxASAiIjJDbACIKjlx4gR2794tZOyVK1fi9ddfN/m4arUaQ4YMwYULF0w+tpLVJbfXX38dK1euFFgV0cPTSOoCiOTkxIkTOHv2LF544QWTjz158mSUlpaafFwiorpgA0BUR3fu3EHjxo0NPr9t27YCqyEiMg4bAKL/WrlyJeLi4gAAQ4YMAQA4Oztj165duHDhAubOnYu3334bCQkJOHXqFJo2bYrPP/8c6enp2LFjB3799Vfk5uaiZcuW6Nu3L15++WU0b95cb3y1Wo1169YBgG7Md955B4mJiTh27BisrKzw5JNPYvbs2bCxsanX17Nnzx58/fXXUKvVsLOzw8CBAzFjxgw0adJE75z9+/dDrVbD2toarq6uePHFFzFgwAAAwJkzZ7B9+3ZcvnwZZWVlaNWqFYYOHYqpU6dW+57Jycn4v//7Pyxbtgz9+/fXe+69997D8ePH8cUXX8DS0hJHjx5FTEwMrl69CktLS7Ru3RqjR4/GyJEjqx07Pj4e//znP7Flyxa4ubnpPffmm28iLy8PUVFRAIDPP/8cP/zwA65evQoA6NChA6ZMmYK+ffvWLcwa/Pbbb9i8eTMuXbqEiooKPPHEE5gxYwY6d+6sOyclJQVbtmzB77//jjt37sDJyQl9+vTB3LlzAQA5OTmIiorC2bNnUVBQAFtbW3Tq1AlhYWFwdHQ0ec1EABsAIp3JkycjLy8Pv/32G5YtWwYAsLKy0jsnMjIS/fr1w+LFi3XT+Tdu3ECbNm0wZMgQ2Nra4saNG/jiiy+wYMECREZG1vq+kZGR6N+/P5YsWYKMjAxERUXB3t4e06dPr/PXsnXrVkRHR2PMmDHo168fLl++jK1btyItLQ3vvfceLCwscOTIEWzcuBFTpkxB9+7dcefOHfzxxx8oKCgAAGRmZmLx4sUYOHAgpkyZgkaNGuHq1avIysp64Pt26dIF7dq1w+HDh/UagNLSUhw7dgzPPPMMLC0t8fPPP2P58uUYM2YM/v73v6O8vBxXrlzBrVu3Hjj2k08+iWbNmuHIkSN6DUBOTg7Onj2Lv//977pjarUaI0aMgIuLC8rLy3HhwgUsXLgQK1asQJ8+feqc6/3++OMPhISE4NFHH8Wbb74JQNt8hISE4MMPP8Rjjz2G4uJihIWFwcPDA2+++SaaNm0KtVqNX375RTfO8uXLcf36dcyaNQutW7dGbm4uzp07hzt37pisVqL7sQEg+q+2bdvCwcEBjRo1gqenZ7XneHp6IjQ0VO+Yj48PfHx8dI/LysrQvXt3TJw4EampqXB3d6/xfb28vDBnzhwAQJ8+fZCRkYFjx47VuQEoKCjArl27EBAQoDeug4MDli9fjsTERPTr1w+XLl2Cm5ub3k/zvr6+ut///vvvKC0txdy5c9GsWTMAQK9evWp9/2HDhmHHjh0oKirSzYAkJiaioKAAw4YNAwBcunQJzZs3x2uvvaZ7XW3fmK2trTFo0CB89913mDlzJiwstGuYv//+ewDA0KFDdefe+8kaAMrLy9GrVy/k5eUhNjbWpA3A9u3bYWVlhXfffVf3tfbu3RtBQUH49NNPsXTpUly5cgWFhYWYNWuWXuMSEBCg+/2vv/6K6dOn6/IBgMGDB5usTqLq8CoAIiM8+eSTVY7dvXsXO3fuxLRp0xAYGAg/Pz9MnDgRAHDlypVax6z8TRcAOnbsiBs3btS5xuTkZJSWlsLPz0/v+NNPPw1LS0vdqvfOnTsjNTUV77//Ps6fP4/i4mK9893d3dGoUSO88847OH78OPLy8gx6/2HDhqG0tBT//ve/dccOHz6MRx99FJ06ddK9d2FhIZYtW4bExEQUFRUZPPZff/2F8+fP643dp08fvany//znP1i0aBHGjh0LPz8/+Pn54dtvvzXoz8MYFy9eRL9+/fQ+6mnWrBn69++vy7lt27Zo3rw51q5di6NHjyI7O7vKOB4eHoiJicG+ffuQnp6OigrepJXE4wwAkRGcnJyqHNu8eTO+/vprTJ06FZ06dULTpk1RXl6O2bNno6SkpNYx7ezs9B5bW1vX62qBe1P499dqaWkJOzs73fP+/v4oKSnBgQMHEBsbC0tLS/j6+uL//u//4OLigrZt22LVqlXYuXMn3nnnHdy9exceHh6YOXMmevTo8cD3d3FxQbdu3XDkyBE8++yzKCoqQkJCAv72t7/pzunRowfefvtt7NmzB4sWLdIde+WVV6p8vl+Zl5cXnJ2dcfjwYXh7e+PPP//E77//rmu4ACA7Oxvz5s2Dh4cH5syZg5YtW6JRo0aIjY3FuXPnjA+0Bvn5+dX+nXByckJhYSEAoHnz5njvvffw6aefYu3atSguLkbHjh0xbdo0DBw4EACwZMkSbNu2DZ999hk2bNiAFi1aYOTIkXjxxRd1Mx1EpsYGgMgIKpWqyrHvv/8eEydO1PsmdO3atYdZlp57DUVOTg46duyoO15WVoaCggLd8yqVCiNHjsTIkSNRVFSExMREbNy4EUuXLsXGjRsBAD179kTPnj1RWlqKn3/+GVu3bkV4eDh27doFe3v7B9YwbNgwrF27Fmq1Gj/++CPKysqqzEgMGjQIgwYNgkajwblz5xAVFYU333wTu3fvfuA3PZVKBT8/P+zbtw9z587F4cOH0axZM72ZmTNnzqCkpATLli2DtbW17vjdu3eNTLJ29vb2yMnJqXI8JycHtra2usfu7u545513UFZWht9++w3R0dFYunQptmzZgo4dO8LR0RFz587F3LlzkZGRgW+//RaffPIJ7O3tMWrUKJPXTQTwIwAiPVZWVgb91F7ZnTt3qiwW/Oabb0xZllG6dOkCKysrxMfH6x2Pj49HWVlZtT+9N2/eHEOHDsWQIUNw+fLlKs9bWVmhV69eCAoKgkajqXEhIKD9/LpRo0Y4evQojhw5gh49eqBVq1bVnmtjY4P+/ftj5MiRuHnzpm6G4kGeeeYZFBcX4/jx4/juu+8waNAgvcsxNRoNLC0t9ZqI3NxcnDx5ssZx66J79+5ITEzE7du3dcdu376N06dPV5uzpaUlPD09MX36dJSXl+PPP/+sck67du0wa9Ys2NraIj093eQ1E93DGQCiSjp06ICCggLExsaic+fOsLa2xmOPPVbja/r27YuYmBjY29vD2dkZiYmJSEhIeEgVV2VnZ4eJEyciOjoaNjY28PHxwZ9//omtW7eie/fuugWL7777Lpo2bYonnngCDg4OuHr1Ko4cOYLevXsDAL7++mskJSXB19cXrVq1Qn5+Pnbu3ImWLVvqzSxUp3nz5ujfvz9iY2Nx8+ZNhIWF6T2/detW5ObmomfPnmjRogWys7Oxb98+uLu7w8HBocax27dvj86dO+Ojjz7CX3/9pbdwDgC8vb2xceNG/Otf/8Jzzz2HnJwcREdHw8HBAWVlZcbGWaOpU6ciISEB8+bNw8SJE6FSqfD555/jzp07usWVp0+fxoEDB/Dkk0+iTZs20Gg02Ldvny77oqIizJ8/H35+fmjfvj0sLS1x8uRJFBYW6v4siERgA0BUybPPPovk5GRs2bIFRUVFun0AajJnzhxs2LABH330Ee7evYuePXti9erVCAoKekhVV/XSSy/Bzs4OX3/9NWJjY2FnZ4eAgABMnz5d95Nx165dcejQIRw5cgS3bt1CixYtMGzYMEybNg0A4ObmhsTERGzevBl5eXmwtbVFt27dsGjRIoM2QBo2bBj+/e9/w8bGRvdZ9z1dunTBvn378MEHH6CwsBAODg7o3bs3XnrpJYO+vmHDhiEyMhLOzs7w8vLSe+7RRx/FP/7xD3zyyScIDw+Hs7Mzxo4di7y8PBw6dMig8Q3VsWNHrFu3Dps3b9ZtEezp6Yl169bpGse2bdvC2toa0dHRuHnzJpo2bQoPDw+sXr0arVq1QklJCR5//HEcOHAA169fh4WFBdq1a4dFixbhqaeeMmm9RJWp4uPjJVtuunPnTuzbtw9FRUXw9vbGvHnzql1QU1xcjLfffhtpaWkoKCiAk5OT7j8qS0tL3XkHDx7U/SPz8PDA/Pnz0a5du4f5JRERETUIkq0BuPfNes6cOYiMjMStW7ewdOnSB57v6+uLZcuWYfv27Xj99dfx7bffYufOnbrnz507hzVr1mDSpEnYtGkTnJycEB4ezr3XiYiIqiHZRwBffvklxo4dq5saDAsLQ3BwcLUbpzRp0gRjxozRPXZxccHQoUP1dtL66quvMHjwYIwYMUI33pgxY5CYmMhpNGqwavvMWqVS8TIxE6ioqEB5eXmN51SebSRSAkkagJKSEqSlpWHWrFm6Y66urnBxccGlS5dq3TktMzMTZ86c0busKDk5WffZJaBtGrp06YLk5GQ2ANRgzZs3D0lJSQ98furUqXp/76lu4uLiEBER8cDnDVkLQtTQSNIAFBQUoLy8vMpNLhwcHGrcbeydd97BiRMnUFJSgueeew7BwcG65/Ly8qqMZ29vj9zc3CrjlJeX4+bNm2jSpEm113UTycUrr7xSZYe+ypycnGrcP58M4+Xlhffee++Bz1tZWTFnkpWKigoUFxejRYsWdZ4FlKQBqOs2l7Nnz8bUqVORlpaGTZs2Ye/evRg3bpzR49y8eVPI/d6JiIgept27dz9wj43aSNIA2Nvbw8LCospP53l5eTVeA+zk5AQnJye0b98ed+/eRWRkpK4BcHBwqDJefn5+tfdgv3c71IyMjCrbsFL9LFy4EMuXL5e6DEVituIwW3GYrRgFBQVo166d3u29jSVJA2BtbQ03NzdcuHAB3t7eAICsrCyo1eoH3oXtfhUVFXrTHl26dMGFCxfw7LPPAtDuBpacnIyxY8dWee29aX87Ozs2ACZmbW3NTAVhtuIwW3GYrVj1+RhbsuXDo0ePxt69e3H8+HGkpqZi9erV6N69O9zd3ZGcnIwpU6bo7pp18eJFHDhwAOnp6cjKysIPP/yALVu24Omnn9aNN2rUKMTHx+Obb75Beno6Vq1ahRYtWujdppXE4+ek4jBbcZitOMxWviS7DHD48OHIzc3FunXrdBsBzZ8/H4B2b/WMjAzdJVDW1tY4fPgwNm3ahLt378LZ2RkjR47EhAkTdON5e3sjNDQU27dvR05ODrp06YIVK1ZU2aOdxDL0lrFkPGYrDrMVh9nKl6Q7AUrl1q1bGDFiBPLz8zk1RUREDU5BQQHs7e1x4MABNGvWrE5jcAcRIiIiM8SbARER0QNpNBqjb5FNpmFtbQ0bGxth47MBIJOKiorS2+GRTIfZisNsq6fRaNCxY0eo1WqpSzFLLi4uSE9PF9YEsAEgk7r/1qxkOsxWHGZbvZKSEqjVau6ZIoF71/mXlJSwAaCGwdfXV+oSFIvZisNsa8Y9U5SJiwCJiIjMEBsAMqmUlBSpS1AsZisOsyVzxAaATCo2NlbqEhSL2YrDbMkcsQEgk3rzzTelLkGxmK04zJbMERsAIiIyG1999RXWrl1r8nGnTZuGwYMHm3xckXgVABERmY2vvvoKR48eRWhoqEnH/cc//oE7d+6YdEzROANAJhURESF1CYrFbMVhtnS/4uJio853c3Mz+Hb2csEGgExq1KhRUpegWMxWHGZrHqZNm4ZPP/0U165dg0qlgkqlwqOPPopjx45BpVJh7969eOmll9CiRQvdN/NffvkFQUFB6NChA5o0aQJ3d3e8+uqryM/PrzJ25Y8A7o0ZGxuLWbNmwdHREc7Ozpg1axZu3779ML/sB+JHAGRSHh4eUpegWMxWHGZrHv7xj38gOzsbP/74I77++msAQOPGjXXfzOfMmYPnnnsOn3/+uW46PyMjA4899hgmTJgAJycnZGRkYM2aNRg+fDhOnjxZ63uGhITgueeeQ0xMDH777TeEhYWhZcuWWLZsmbgv1EBsAIiIqN4qKoDCQnHj29oCKlX9xnBzc0OrVq1gbW2tt/vjsWPHAAD9+vXDpk2b9F4TGBiIwMBA3eO7d+9iwIAB6NChAy5cuIAePXrU+J6DBg3Chg0bAADPPPMMfvvtN+zevVsWDQA/AiCTSkhIkLoExWK24jDb+issBOztxf0S2VzcU91HQaWlpVi5ciU8PT3RrFkzWFlZoUOHDgAM20Dq2Wef1XvcrVs3ZGRkmKbgeuIMAJlUUlIS91UXhNmKw2zrz9YWuO9jcZOPL5qLi0uVY+Hh4di4cSPefvtteHt7w9bWFuXl5fD19YVGo6l1TCcnJ73HjRs3ls3VAmwAyKR4S1VxmK04zLb+VCqgod8vSFXNZwy7du1CWFgY3njjDd2xtLS0h1mWMPwIgIiIzEbjxo2NusTv9u3baNy4sd6xzZs3m7osSXAGgIiIzIanpydycnKwceNG9O7dGzY2NjWeHxgYiNWrV6NVq1Zo3749vv32W3zzzTcPqVqxOANAJhUeHi51CYrFbMVhtuZj+vTpmDhxIhYuXIi+ffviueeeq/H8DRs2IDAwEGFhYRg7dizS09Nx5MiRh1StWKr4+PgKqYt42G7duoURI0YgPz8fdg39QyuZUavV1S6kofpjtuIw2+oVFBTA3t6e/1dKoLbs7z1/4MABNGvWrE7vwRkAMin+JyoOsxWH2ZI5YgNARERkhtgAkEnFxcVJXYJiMVtxmC2ZIzYAZFJ5eXlSl6BYzFYcZkvmiA0AmdSECROkLkGxmK04zJbMERsAIiIiM8QGgEzKkL2xqW6YrTjMlswRGwAyqYULF0pdgmIxW3GYLZkjNgBkUsuXL5e6BMVituIwWzJHbADIpGrbV5vqjtmKw2zJHLEBICIiMtLly5ehUqlw7NgxqUupMzYAZFIxMTFSl6BYzFYcZkvmiA0AmZSDg4PUJSgWsxWH2ZI5YgNAJuXv7y91CYrFbMVhtuZh9+7dUKlUuHjxYpXnAgMD0bt3bwDAqlWr4OPjA0dHRzg6OqJ///6K3C6aDQAREZmFkSNHwt7eHjt27NA7fv36dRw9ehSTJ08GoP18f+bMmdizZw9iYmIwaNAgjBgxAocPH5aibGEaSV0AKQvvqy4OsxWH2dZfRUUFCksKhY1va20LlUpVrzFsbGwwbtw47Ny5EytXroSFhfZn4M8//xwAEBQUBAD48MMPda8pLy/H008/jezsbHz44Yd45pln6lWDnLABIJNav349VqxYIXUZisRsxWG29VdYUgj7lfbCxs9fkA+7xnb1Hmfy5Mn4+OOP8f3338PPzw8AEB0dDX9/f7Ru3RoAcO7cOSxduhRnzpzB9evXUVFRAQDo3Llzvd9fTtgAkEnxP1FxmK04zLb+bK1tkb8gX+j4pjBw4EB06NAB0dHR8PPzQ3JyMs6dO4ddu3YBAK5evYqhQ4eiT58+2LBhA9q2bQsrKyts3LgR3333nUlqkAs2AEREVG8qlcokP6GLplKpEBwcjPfffx8bN25EdHQ07OzsMHLkSADAoUOHoNFosH//fjRu3Fj3upKSEqlKFoaLAImIyKxMnjwZRUVF2LdvHz777DOMHz8eTZo0AQDcvn0bjRo10q0PAIAbN24gNjZWqnKFkawB2LlzJ8aNG4eAgAAsWrQIOTk51Z6nVqsRERGBiRMnwt/fH1OnTq3yB3Ho0CEMGTJE79f06dMfxpdB94mKipK6BMVituIwW/Pi4eGB3r17Y8GCBbhy5Ypu9T8A+Pn5QaPRIDg4GEePHsWOHTswYMAA3foAJZHkI4CDBw8iOjoa4eHhcHV1RWRkJJYuXYr169dXOffKlSuwsLDAG2+8gTZt2uDXX3/FmjVrYGNjo3ftbosWLfDRRx/pHltaWj6Ur4X0eXl5SV2CYjFbcZit+Zk8eTJCQkLQvn17DBw4UHfc09MTu3btwpIlSzBixAi0b98er7/+Om7cuIFt27ZJV7AAqvj4+IqH/aYzZ85E3759dT+lZ2ZmIjg4GJs3b4a7u3utr1+zZg3y8/Pxz3/+E4B2BuDjjz/GF198YdD737p1CyNGjEB+fj7s7OT/mRURkRQKCgpgb2/P/yslUFv2954/cOAAmjVrVqf3eOgfAZSUlCAtLQ09e/bUHXN1dYWLiwsuXbpk0Bj5+fmwtbWtcmz8+PEICgrCsmXLkJ2dbdK6iYiIlOShNwAFBQUoLy+Ho6Oj3nEHBwfk5eXV+vpLly4hISEBgYGBumPt27dHWFgYVq5cifnz5+P69euYO3euIldtyl1KSorUJSgWsxWH2ZI5eugNwL0NFeoiIyMDixcvxrRp09C1a1fdcU9PT/j5+cHNzQ3e3t5Yvnw5cnNzcfr06RrHGz9+PEJDQxEaGor9+/cjNDQUGo1G93xMTIze/s9qtRrh4eF6Y0RFRSEhIUH3OCUlBREREXrnRERE6P0Hk5CQUGXRUXh4ONRqte5xXFyc3h3KNBpNg6hvz549sq5P7vnVVN+OHTtkXZ/c86upvnsLi+Va3z0Pu76jR4+CpPXee+/p/nzj4uIQFBQEPz8/LFy4sN5jP/Q1ACUlJQgMDMSqVavg7e2tOx4UFISgoCDdtZj3y8zMxOuvv45hw4ZhxowZtb7PjBkzMHToUEycOLHKc1wDQERUO64BkI4i1wBYW1vDzc0NFy5c0B3LysqCWq2Gp6dnta+5fv06QkND8dRTTxn0zf/27dvIysri3t5EREQPIMk+AKNHj8bevXtx/PhxpKamYvXq1ejevTvc3d2RnJyMKVOm6BbxZWdnIzQ0FG5ubggODkZOTg5ycnJQUFCgG2/79u04e/YssrKycOnSJbz11luws7ODj4+PFF8eERGR7EmyD8Dw4cORm5uLdevWoaioCN7e3pg/fz4A4M6dO8jIyEBZWRkA4OzZs8jMzERmZiZOnTqlG8PLywvr1q0DABQWFiIiIgJ5eXmwt7dHt27dsHbtWt3OTvTwRERE4M0335S6DEVituIwWzJHkuwDIDWuARAnJSUFHh4eUpehSMxWHGZbvXufM2dkZPD/yoesoKAA7dq1E7oGgDcDIpPif6LiMFtxmG31rK2t4eLignbt2kldillycXGBtbW1sPHZABARUbVsbGyQnp7OPVUkYm1tDRsbG2Hjm3UDwL/TppeQkABfX1+py1AkZisOs30wGxuben0TYrbyZda3A+ZuwaaXlJQkdQmKxWzFYbbiMFv5MutFgPHx+Rg8mAtbiIioYWmQGwHJCWcAiIjIXJl1A3D9utQVEBERScOsG4AbN6SuQHnuv5kJmQ6zFYfZisNs5YsNAJlUSEiI1CUoFrMVh9mKw2zliw0AmRRvwCQOsxWH2YrDbOXLrBsArgEgIiJzZdYNAGcATC8uLk7qEhSL2YrDbMVhtvLFBoBMKi8vT+oSFIvZisNsxWG28mXWGwEB+SgutoPArZaJiIhMjhsB1ZNKxXUARERknsy6AWjZkg2AqWk0GqlLUCxmKw6zFYfZypdZNwCtWwNqtdRVKMvChQulLkGxmK04zFYcZitfZr0G4Omn8zFxoh1mzJC6IuXQaDRC719tzpitOMxWHGYrBtcA1FOrVpwBMDX+QxeH2YrDbMVhtvJl1g2AszPXABARkXky6waAawBMLyYmRuoSFIvZisNsxWG28mX2DQBnAEzLwcFB6hIUi9mKw2zFYbbyZfYNAGcATMvf31/qEhSL2YrDbMVhtvJl1g0A1wAQEZG5MusGoHVroLAQuH1b6kqUQ80pFWGYrTjMVhxmK19m3QA4OQGWlpwFMKX169dLXYJiMVtxmK04zFa+zHojoPz8fHh42GHvXqBfP6mrIiIiMgw3AjIBFxfOABARkfkx+wbA2ZlXAhARkfkx+waAMwCmFRUVJXUJisVsxWG24jBb+WID4MIZAFPy8vKSugTFYrbiMFtxmK18mX0DwL0ATMvX11fqEhSL2YrDbMVhtvJl9g0AZwCIiMgcmX0DwBkA00pJSZG6BMVituIwW3GYrXyZfQPAGQDTio2NlboExWK24jBbcZitfJn9RkB379qhRQvtlsDNm0tdGRERUe24EZAJODoCVlacBSAiIvNi9g2ASsV1AEREZH7MvgEAuA7AlCIiIqQuQbGYrTjMVhxmK19sAMAZAFMaNWqU1CUoFrMVh9mKw2zliw0AOANgSh4eHlKXoFjMVhxmKw6zlS82AOAMABERmR9JG4CdO3di3LhxCAgIwKJFi5CTk1PteWq1GhEREZg4cSL8/f0xderUaq8tPXjwICZNmgR/f3+EhIQgIyPDoDo4A2A6CQkJUpegWMxWHGYrDrOVL8kagIMHDyI6Ohpz5sxBZGQkbt26haVLl1Z77pUrV2BhYYE33ngDn3zyCV588UVs3LgRcXFxunPOnTuHNWvWYNKkSdi0aROcnJwQHh6O0tLSWmvhDIDpJCUlSV2CYjFbcZitOMxWviTbCGjmzJno27cvpk+fDgDIzMxEcHAwNm/eDHd391pfv2bNGuTn5+Of//wnAGDJkiWwtrbG4sWLAQDFxcUYM2YMFi9ejKeeekrvtZU3ArKzs8MPPwBTpgCXL5v2ayQiIhKhwW4EVFJSgrS0NPTs2VN3zNXVFS4uLrh06ZJBY+Tn58PW1lb3ODk5WW+8Jk2aoEuXLkhOTq51rHszABVmtyciERGZK0kagIKCApSXl8PR0VHvuIODA/Ly8mp9/aVLl5CQkIDAwEDdsby8vCrj2dvbIzc3t9bxXFwAjQYoKDDwCyAiImrgJGkAKurxo3ZGRgYWL16MadOmoWvXriapx84OaNyY6wBMITw8XOoSFIvZisNsxWG28iUO5ckGAAAgAElEQVRJA2Bvbw8LC4sqP53n5eXBwcHhga/LzMzEvHnzEBgYiEmTJuk95+DgUGW8/Pz8KrMClY0fPx6hoaGYNy8Udnb7sXhxKDQaje75mJgYvYWGarW6yl/mqKgovVWuKSkpVXa+ioiI0LslZkJCAqKiovTOCQ8Ph7rSpQhxcXGIiYnRPdZoNAgNlX99s2bNknV9cs+vpvqCgoJkXZ/c86upvpCQEFnXd09DrM/S0lLW9ck9v8r1xcXFISgoCH5+fli4cCHqS9JFgD4+Pnj55ZcBAFlZWZg0adIDFwFev34dISEh6N+/P+bMmVPl+SVLlqBx48ZYtGgRAO0fyOjRow1aBAgAPj7AvHnACy+Y+islIiIyrQa7CBAARo8ejb179+L48eNITU3F6tWr0b17d7i7uyM5ORlTpkxBdnY2ACA7OxuhoaFwc3NDcHAwcnJykJOTg4JKH9qPGjUK8fHx+Oabb5Ceno5Vq1ahRYsW8PHxMageFxd+BEBEROajkVRvPHz4cOTm5mLdunUoKiqCt7c35s+fDwC4c+cOMjIyUFZWBgA4e/YsMjMzkZmZiVOnTunG8PLywrp16wAA3t7eCA0Nxfbt25GTk4MuXbpgxYoVsLKyMqgeZ2duBmQKcXFx8Pf3l7oMRWK24jBbcZitfEnWAABAcHAwgoODqxzv0aMH4uPjdY8DAgIQEBBQ63jDhw/H8OHD61SLiwuQmVmnl1IlhlzFQXXDbMVhtuIwW/nivQD+izMApjFhwgSpS1AsZisOsxWH2coXG4D/4hoAIiIyJ2wA/oszAKZR+TIYMi1mKw6zFYfZyhcbgP+6NwPA7YDrxxTXplL1mK04zFYcZitfku0DIKXq9gEoLNTuCHjzJuDkJHGBDZhGo4GNjY3UZSgSsxWH2YrDbMVo0PsAyE3z5kDTplwHUF/8hy4OsxWH2YrDbOWLDcB/qVRcB0BEROaDDUAlvBKg/irvj02mxWzFYbbiMFv5YgNQCWcA6q+mmzlR/TBbcZitOMxWvtgAVMIZgPrjlp/iMFtxmK04zFa+2ABUwhkAIiIyF2wAKuEMQP2p2UEJw2zFYbbiMFv5YgNQCWcA6m/9+vVSl6BYzFYcZisOs5UvbgT0342AAOD0aWDcOODaNQmLIyIiqgU3AjIxZ2ftRwDl5VJXQkREJBYbgEqcnYGyMiAnR+pKiIiIxGIDUEmzZtotgbkOoO6ioqKkLkGxmK04zFYcZitfbADuwysB6sfLy0vqEhSL2YrDbMVhtvLFBuA+vBKgfnx9faUuQbGYrTjMVhxmK19sAO7DGQAiIjIHbADuwxmA+klJSZG6BMVituIwW3GYrXyxAbgPZwDqJzY2VuoSFIvZisNsxWG28sWNgCptBAQAH30E7N0LxMVJVBwREVEtuBGQAJwBICIic8AG4D5cA0BEROaADcB9XFyA7GztjoBkvIiICKlLUCxmKw6zFYfZyhcbgPs4O2vvBfDXX1JX0jCNGjVK6hIUi9mKw2zFYbbyxQbgPjY2gL091wHUlYeHh9QlKBazFYfZisNs5YsNQDW4DoCIiJSODUA1eCVA3SUkJEhdgmIxW3GYrTjMVr7YAFSDMwB1l5SUJHUJisVsxWG24jBb+WIDUA3OANTdrFmzpC5BsZitOMxWHGYrX2wAqsEZACIiUjo2ANXgDAARESkdG4BqcAag7sLDw6UuQbGYrTjMVhxmK19sAKrBGYC6CwkJkboExWK24jBbcZitfLEBqIazs3YnwLt3pa6k4XFxcZG6BMVituIwW3GYrXyxAahG69ZARYX2ngBERERKxAagGo0bA46OXAdQF3FxcVKXoFjMVhxmKw6zlS+jGoADBw7g5MmTuscbNmxAYGAgZs2ahatXr5q8OClxHUDd5OXlSV2CYjFbcZitOMxWvoxqAD7//HM0a9YMgHZ3p7i4OLz55pto164dIiMjhRQoFV4JUDcTJkyQugTFYrbiMFtxmK18GdUA/PXXX3B1dQUAnDhxAkOGDMHgwYMxdepUXLp0SUiBUuEMABERKZlRDYCdnR3++usvAMCZM2fQp08fAEBFRQXKy8tNX52EOANQNxqNRuoSFIvZisNsxWG28mVUA/DMM8/gnXfewRtvvIHbt2/Dx8cHAHDp0iW0a9fOqDfeuXMnxo0bh4CAACxatAg5OTkPPPf999/Hyy+/jKFDh2LZsmVVnj906BCGDBmi92v69OlG1XM/zgDUzcKFC6UuQbGYrTjMVhxmK1+NjDl5xowZcHd3R3Z2NubNm4fGjRsDAFQqFYKDgw0e5+DBg4iOjkZ4eDhcXV0RGRmJpUuXYv369dWer1KpMGrUKJw4ceKBY7Zo0QIfffSR7rGlpaXB9VSHMwB1s3z5cqlLUCxmKw6zFYfZypdRDQAADBkyRO9xfn4+nnnmGahUKoPH+PLLLzF27FgMHDgQABAWFobg4GCkpqbC3d29yvmvvfYaAO1MQ1lZWbVjqlQqODk5GVxDbTgDUDc2NjZSl6BYzFYcZisOs5Uvoz4C+PTTT3H06FHd48WLF2PMmDEYO3YsfvvtN4PGKCkpQVpaGnr27Kk75urqChcXl3otJMzPz8f48eMRFBSEZcuWIbueu/hwBoCIiJTMqAbg22+/1V0FkJCQgOTkZHz44Yfw8/PDhx9+aNAYBQUFKC8vh6Ojo95xBweHOl8v2r59e4SFhWHlypWYP38+rl+/jrlz56KkpKRO4wHaGYCcHKAeQ5ilmJgYqUtQLGYrDrMVh9nKl1ENQG5uLlq1agUAOH36NIYMGQIPDw+MHj0aqampBo1RUVFhfJW18PT0hJ+fH9zc3ODt7Y3ly5cjNzcXp0+frvF148ePR2hoKEJDQ7F//36EhobqVqxqv8wY7N79v12s1Gp1lTtbRUVFISEhQfc4JSUFEREReudEREQgJSVF9zghIQFRUVF654SHh0NdacohLi5O7x+ORqPRqw/Q/sOqvMuWHOpr2rSprOuTe3411VdeXi7r+uSeX031OTg4yLq+expifYcPH5Z1fXLPr3J9cXFxCAoKgp+fn0kWV6ri4+MN/o48adIkzJs3Dz179sSkSZMQGhqKvn37Ij09HSEhIfj6669rHaOkpASBgYFYtWoVvL29dceDgoIQFBSEkSNHPvC1K1euRFlZGRYtWlTr+8yYMQNDhw7FxIkTqzx369YtjBgxAvn5+bCzs3vgGK1aAYcOAZXKJCIiklxBQQHs7e1x4MAB3QZ9xjJqEeDzzz+Pt956Cy1atEDjxo1138CTkpLQsWNHg8awtraGm5sbLly4oHt9VlYW1Go1PD09jSy/erdv30ZWVla970LFdQBERKRURjUA48aNQ9euXXHjxg14e3vrLrVzdnY26rr70aNHIzIyEp06dUKbNm3w4Ycfonv37nB3d0dycjJWrFiBNWvW6D5uuHbtGoqLi1FYWIiysjKkpqaiUaNGePTRRwEA27dvxxNPPAFXV1fk5ubik08+gZ2dnW6fgrrilQDGU6vVvP2nIMxWHGYrDrOVL6MvA/Tw8ICHhweKiopQVFSE5s2bo1+/fkaNMXz4cOTm5mLdunUoKiqCt7c35s+fDwC4c+cOMjIy9C73W716NZKSknSPExMT4ezsjF27dgEACgsLERERgby8PNjb26Nbt25Yu3YtmjRpYuyXp4czAMZbv349VqxYIXUZisRsxWG24jBb+TJqDUB5eTl27dqFPXv2ID8/HwBgb2+P8ePHY8KECbCwaBh3FzZ0DcC8ecDdu8AD9iciIiKSxENfA/DRRx/h8OHDmDZtGp544gkAwK+//opt27ahsLAQM2fOrFMRcuXsDJw9K3UVREREpmdUA3D48GEsWLAAffv21R1zc3ODs7MzIiIiFNcAcA0AEREplVFz9rdv30br1q2rHG/dujWKi4tNVpRccA2A8e6/fpZMh9mKw2zFYbbyZVQD0K1bN2zZsgVFRUW6Y0VFRfj444/RtWtXkxcnNc4AGM/Ly0vqEhSL2YrDbMVhtvJl1CLAa9euYdGiRbh+/Tratm0LALh69SpcXFywbNky3TG5M3QRoFoNtGkDFBcDvJ8FERHJxUNfBNi2bVts3boVP/30EzIyMlBRUYH27dujT58+Rt0NsKFo1QqwsABu3ADat5e6GiIiItOptQHYunVrjc//8ssv+OWXXwAAL730kmmqkglLS6BlS+1MABsAw6SkpMDDw0PqMhSJ2YrDbMVhtvJVawPw888/GzSQEmcAAK4DMFZsbCz/sQvCbMVhtuIwW/kyag2AUhi6BgAAnnkGGD8emDHjIRVHRERUC1OsAWgYW/dJiDMARESkRGwAasG9AIiISInYANSCMwDGiYiIkLoExWK24jBbcZitfLEBqAVnAIwzatQoqUtQLGYrDrMVh9nKFxuAWnAGwDhc7SsOsxWH2YrDbOWLDUAtOANARERKxAagFi4uQGEhcPu21JU0DAkJCVKXoFjMVhxmKw6zlS82ALVo0UK7IyA/BjBMUlKS1CUoFrMVh9mKw2zlixsB1bIREAC4ugL79gG+vg+hOCIiolpwI6CHhOsAiIhIadgAGIBXAhARkdKwATAAZwAMFx4eLnUJisVsxWG24jBb+WIDYADOABguJCRE6hIUi9mKw2zFYbbyxQbAAJwBMJyLi4vUJSgWsxWH2YrDbOWLDYABOANARERKwwbAAJwBMFxcXJzUJSgWsxWH2YrDbOWLDYABOANguLy8PKlLUCxmKw6zFYfZyhc3AjJgI6CcHO2OgIWFQPPmD6FAIiKiGnAjoIfE0RGwsuIsABERKQcbAAOoVFwHYCiNRiN1CYrFbMVhtuIwW/liA2AgZ2fOABhi4cKFUpegWMxWHGYrDrOVLzYABnJx4QyAIZYvXy51CYrFbMVhtuIwW/liA2AgzgAYxsbGRuoSFIvZisNsxWG28sUGwECcASAiIiVhA2AgzgAYJiYmRuoSFIvZisNsxWG28sUGwECcATCMg4OD1CUoFrMVh9mKw2zliw2AgTgDYBh/f3+pS1AsZisOsxWH2coXGwAD3ZsBqDC7fROJiEiJ2AAYyNkZ0Gi02wHTg6n5OYkwzFYcZisOs5UvNgAGsrcHGjfmOoDarF+/XuoSFIvZisNsxWG28sWbARlwM6B7OnQAduwABgwQWBwREVEteDOgh4xXAhARkVKwATACrwQgIiKlkLQB2LlzJ8aNG4eAgAAsWrQIOTk5Dzz3/fffx8svv4yhQ4di2bJl1Z5z8OBBTJo0Cf7+/ggJCUFGRoZJ6+UMQO2ioqKkLkGxmK04zFYcZitfkjUABw8eRHR0NObMmYPIyEjcunULS5cufeD5KpUKo0aNgre3d7XPnzt3DmvWrMGkSZOwadMmODk5ITw8HKWlpSarmTMAtfPy8pK6BMVituIwW3GYrXxJ1gB8+eWXGDt2LAYOHAh3d3eEhYXh4sWLSE1Nrfb81157DSNHjoSTk1O1z3/11VcYPHgwRowYgY4dOyIsLAx//fUXEhMTTVYzZwBq5+vrK3UJisVsxWG24jBb+ZKkASgpKUFaWhp69uypO+bq6goXFxdcunSpTmMmJyfrjdekSRN06dIFycnJ9a73Hs4AEBGRUkjSABQUFKC8vByOjo56xx0cHJCXl1enMfPy8qqMZ29vj9zc3DrXeT/OANQuJSVF6hIUi9mKw2zFYbbyJUkDUCGT/XTHjx+P0NBQhIaGYv/+/QgNDYVGo9E9HxMTg7i4ON1jCws1rl0L19sOOCoqCgkJCbrHKSkpiIiI0HufiIgIvX8ECQkJVRbGhIeH6+2YFRcXp3cXLY1GU2t9arUa4eHheuM+7Pr27Nkj6/rknl9N9e3YsUPW9ck9v5rqi42NlXV99zTE+ubOnSvr+uSeX+X64uLiEBQUBD8/PyxcuBD1JclGQCUlJQgMDMSqVav0FvUFBQUhKCgII0eOfOBrV65cibKyMixatEjv+Pjx4zFt2jQ8++yzumNz586Fp6cnZsyYoXduXTcCKiwE7OyAnBzgvskGIiKih6bBbgRkbW0NNzc3XLhwQXcsKysLarUanp6edRqzS5cueuNpNBokJyejS5cu9a73nubNgSZNuA6AiIgaPsmuAhg9ejT27t2L48ePIzU1FatXr0b37t3h7u6O5ORkTJkyBdnZ2brzr127htTUVBQWFqKwsBCpqam4fPmy7vlRo0YhPj4e33zzDdLT07Fq1Sq0aNECPj4+JqtZpeI6ACIiUgbJGoDhw4cjODgY69atw+zZs2FjY4O33noLAHDnzh1kZGSgrKxMd/7q1asxY8YMnDp1ComJiZgxYwYWLFige97b2xuhoaGIjo7GrFmzcPPmTaxYsQJWVlYmrZtXAtTs/s+vyHSYrTjMVhxmK1+8GZARawAAYMwYYPBgICRETG0NXUpKCjw8PKQuQ5GYrTjMVhxmK0aDXQPQkHEGoGb8hy4OsxWH2YrDbOWLDYCRuAaAiIiUgA2AkTgDULPK17SSaTFbcZitOMxWvtgAGIkzADVLSkqSugTFYrbiMFtxmK18cRGgkYsAT50CXngBuHpVUHFERES14CJACbi4aD8CKC+XuhIiIqK6YwNgJGdn4O5dwIT3GCIiInro2AAYqVkz7ZbAXAdQvftvdkGmw2zFYbbiMFv5MusGoKikqE6v45UADxbCHZKEYbbiMFtxmK18mXUDcOLKiTq9jlcCPJiLi4vUJSgWsxWH2YrDbOXLrBuA7/74rk6v4wwAERE1dGbdABz942idXscZgAeLi4uTugTFYrbiMFtxmK18mXUDcCX/Cv7I/cPo13EG4MHy8vKkLkGxmK04zFYcZitfZt0A+Dzig7hU47tTzgA82IQJE6QuQbGYrTjMVhxmK19m3QD4PeaHuDTjGwDOABARUUNn1g3A0I5D8X369ygtKzXqdZwBeDCNRiN1CYrFbMVhtuIwW/ky6wagm3M3NLFqgtNXTxv1OmdnIDsbKCsTVFgDtnDhQqlLUCxmKw6zFYfZypfZ3wxo9nez0c6uHZYPXW7w64uLgaZNtR8DtG4tsNAGSKPRwMbGRuoyFInZisNsxWG2YvBmQCYQ4BZg9DqAJk0AOzuuA6gO/6GLw2zFYbbiMFv5MvsGYJjbMFxQX8CNWzeMeh3XARARUUNm9g1A62at0cOlB46kHTHqdbwSoHoxMTFSl6BYzFYcZisOs5Uvs28AAMDfzd/ojwE4A1A9BwcHqUtQLGYrDrMVh9nKFxsAAAHu2nUA5RXlBr+mfXvgl18EFtVA+fv7S12CYjFbcZitOMxWvtgAAOj3SD8UlxYjSZ1k8GumTQNiYjgLQEREDRMbAABWllZ4uuPTRn0M0LUr8PTTwIYNAgtrgNTsiIRhtuIwW3GYrXyxAfivuqwDCAsDPvwQKCwUVFQDtH79eqlLUCxmKw6zFYfZypfZbwRkZ2cHAPgj9w90juyMnLAc2Da2NWicigrA1xeYOBGYO1dkxURERP/DjYBM6DHHx9DRoSPiL8cb/BqVSjsLsHYtUGrc7QSIiIgkxQagEn83f6NvDzx6NGBjA+zaJagoIiIiAdgAVOLvbvw6AEtLYP58YPVq7UcC5i4qKkrqEhSL2YrDbMVhtvLFBqCSwY8OxpX8K0jNSTXqdVOmaHcFjDOud1AkLy8vqUtQLGYrDrMVh9nKFxuASppbN8eADgOM/higSRNgzhxg1SpBhTUgvr6+UpegWMxWHGYrDrOVLzYA96nL5YAA8MorwJkzwI8/CiiKiIjIxNgA3MffzR/xl+NRUlZi1OucnIDp07VrAcxZSkqK1CUoFrMVh9mKw2zliw3Afbo7d0dz6+Y4lXHK6NfOnQvExgKpxi0hUJTY2FipS1AsZisOsxWH2coXNwL670ZAlU39airaNG+DlX4rjR77xRcBOzvtDoFEREQicCMgQQLcAuq0DgAA3ngD2LYNuHHDtDURERGZEhuAagxzG4aL1y/ietF1o1/r5QUMHAh88IGAwoiIiEyEDUA1WjZtiV5teuFw2uE6vT4sDIiMBG7dMnFhDUBERITUJSgWsxWH2YrDbOWLDcAD1PVyQAAYMgTo2BHYutXERTUAo0aNkroExWK24jBbcZitfLEBeIAAd+06gPKKcqNfe+8mQWvWAHfvCihOxjw8PKQuQbGYrTjMVhxmK19sAB7Ap60PSspKcD7rfJ1e//zzgIUF8MUXJi6MiIjIBCRtAHbu3Ilx48YhICAAixYtQk5OzgPPzcnJweLFixEQEICxY8dix44des9v27YNQ4YM0fu1ePHiOtdmZWmFoR2H1vljgEaNgHnztNsDm9NNghISEqQuQbGYrTjMVhxmK1+SNQAHDx5EdHQ05syZg8jISNy6dQtLly594PlLly5FYWEhIiMj8frrr2Pnzp349ttv9c7x8PDA3r17db8WLFhQrxrrsw4AAP72NyAjAzh6tF5lNChJSUlSl6BYzFYcZisOs5UvyRqAL7/8EmPHjsXAgQPh7u6OsLAwXLx4EanVbKOXlpaGixcvYv78+XB3d8eAAQMwbtw47Nu3T++8Ro0awcnJSferefPm9arR390fpzJOoeBOQZ1e37Qp8Npr5nWToFmzZkldgmIxW3GYrTjMVr4kaQBKSkqQlpaGnj176o65urrCxcUFly5dqnJ+SkoKWrVqhXbt2umO9erVC+np6bhz547uWFpaGp5//nlMnjwZ69atQ2FhYb3qfNThUbg5uuH79O/rPMbs2cCpU8D5ui0lICIiEkKSBqCgoADl5eVwdHTUO+7g4IC8vLwq5+fm5sLBwaHKueXl5cjPzwcAeHp6Ijw8HO+++y5eeeUVJCUlYfHixaio5wfw/m7+Rt8euLKWLYGXXuJNgoiISF4kaQDq+025On379sWAAQPw2GOPoX///vjXv/6Fixcv4j//+U+9xvV3164DqE/NoaHA3r1Aenq9SmkQwsPDpS5BsZitOMxWHGYrX5I0APb29rCwsEBubq7e8by8vCo/6QOAo6NjlZmBvLw8WFhYwN7evtr3aNu2LZo3b46srKwH1jF+/HiEhoYiNDQU+/fvR2hoKDQaje75mJgYlP5WimuF15Cakwq1Wl3lL3NUVJTeKteUlJQqO1/t3h0BP78UvPee9nFCQgKioqL0zgkPD4dardY9jouLQ0xMjO6xRqOptr64uP/NTtS1voiICL1bdtanvsqf98mxPrnnV1N9QUFBsq5P7vnVVF9ISIis67unIdZnaWkp6/rknl/l+uLi4hAUFAQ/Pz8sXLgQ9SXZ3QBnzpwJHx8fvPzyywCArKwsTJo0CZs3b4a7u7veuWlpaZg+fTqio6PxyCOPAAA++eQTnDx5Elu2bKl2/OvXr2PixInYuHFjlY0oarsb4P2GRQ/DyE4j8ZrPa3X5UgEA584BAwYAf/6p/ViAiIiorhr03QBHjx6NvXv34vjx40hNTcXq1avRvXt3uLu7Izk5GVOmTEF2djYAwM3NDd27d8e7776L1NRUnDhxAnv27MHzzz+vG2/Tpk34+eefoVarcf78eSxZsgRPPPEEOnXqVO9a63s5IAD06gX068fbBBMRkTxI1gAMHz4cwcHBWLduHWbPng0bGxu89dZbAIA7d+4gIyMDZWVluvPfeustNGvWDK+++irWrl2LoKAgDB8+XPf89evX8fbbb2Py5MmIiIhAp06d8K9//QsWFvX/Ev3d/BF/OR537t6p/eQahIUBGzYAt2/XuyTZqjzlRabFbMVhtuIwW/lqJOWbBwcHIzg4uMrxHj16ID4+Xu+Yk5MTli1b9sCx7jUPInRt3RUONg44mXEST3d8us7jDBsGtG0LfPop8MorJixQRqq7ioNMg9mKw2zFYbbyxXsBGEClUsHfzR+HUg/VcxztLMC77wKVJjcUZcKECVKXoFjMVhxmKw6zlS82AAYyxToAABg/XvvN/75NDImIiB4qNgAG8nvMD7/c+AVZhQ++rNAQVlbafQEiIpR5k6DKl8GQaTFbcZitOMxWvtgAGKhF0xbo7dobh9MO13usl1/Wbgp07Fj965IbU1ybStVjtuIwW3GYrXxJtg+AlIzdB+CeJfFLkJqTip1jd9a7hiVLgB9/BA4erPdQsqLRaGBjYyN1GYrEbMVhtuIwWzEa9D4ADVGAewAOpx1GWXn9V/C9+qp2BuDixfrXJSf8hy4OsxWH2YrDbOWLDYAR+rbti7vld3Eu61y9x2rdGpg2DVi5sv51ERERGYsNgBEaWTSC32N+JrkaANBeEnj0KDB9OqCUdTKV98cm02K24jBbcZitfLEBMJKpLgcEgI4dtfcI+OWX/90noKGr7mZOZBrMVhxmKw6zlS82AEbyd/fH6YzTyNfkm2S8Rx4B/v1voHdvwNtbOyPQkPn7+0tdgmIxW3GYrTjMVr7YABipvX17dGrRCd+lf2eyMRs3BjZu1O4QOHq0dl2AEvcIICIi+WADUAf+bv6ISzX9DS6mTQOOHweiooDnnwcKCkz+FsJVvmc2mRazFYfZisNs5YsNQB34u2vXAVQI+DG9Z0/gp5+A4mKgTx/g0iWTv4VQ69evl7oExWK24jBbcZitfHEjICM2ArrndultOEU4IenvSejcsrOACrX3C1i6FFi3DtiyBXjhBSFvQ0REDRA3ApJIU6umGPToILx17C0cSj2EnOIck7+HpSXwz38Cn30GzJwJzJsH3L1r8rchIiIzxQagjpY/vRyNLBrhtYOvocWqFui0oROmfDkFH5z5AGczz6K0rNQk7/Pcc9otgw8fBvz8gOvXTTIsERGZOTYAdeTt6o0dz+/A76/9juw3srEuYB06OnTE1//5Gn7RfrBbaYcntz6JeXHzsPvX3biSf6XOawYefxxISABcXYFevbS/l6uoqCipS1AsZisOsxWH2cpXI6kLUIKWTVti+OPDMfzx4QCA8opy/Ofmf5B4NRGJ12zqyv0AACAASURBVBKx8sRKXLx+Ea2atYJPWx/4PuILn7Y+6O3aG7aNbQ16j2bNtB8HvP8+MHQosHo18MorgEol8isznpeXl9QlKBazFYfZisNs5YuLAOuwCLAubpfexrmsc0i4moDEa4lIuJqAzMJMdG3dFU+1ewoDOwzEgA4D4GrrWutYx48D48cD/v7Apk1AkyYP4QsgIiLZMMUiQM4APCRNrZriqfZP4an2T+mOZRZm4nTGaRy/chwRJyMwad8kdHToiAEdBmBge21D4OboBtV9P+YPGKDdQviFF4D+/YG9e4HHHnvYXxERETVkbAAk5GrrirGeYzHWcywAIF+Tj1MZp3D8ynF8fP5j/P2bv8OpiZN2dqD9AAxoPwDdnLvBQmUBV1fg+++B+fO1WwibYpbN11d75YG1dd3HSElJgYeHR/2LoSqYrTjMVhxmK19sAGTE3sYegY8HIvDxQABAcWkxfsz8ET/8+QP2/2c/FhxdACtLKzzZ7kkMaD8AAzsMxLvveWPMGGtcvVr7+DWtFygv1+45EB8P7N4NdOhQt68hNjaW/9gFYbbiMFtxmK18cQ3AQ1oDYAp3y+/igvoCjv95HD9c+QHH/zyO26W34fuIL5YOXooBHQbUa3yNBpg7F4iJAaKjgWefNVHhRERkUtwIyMw0smiE3q69MbffXHw54Utkv5GNn2b+BL/H/BDwWQCWH1+O8oryOo9vY6O9KVFkJBAUBISHc/MhIiKlYgPQgKlUKni28sTCAQvxw7QfsPX8VgR+Fogbt27Ua9xJk4AzZ4D9+4GnnwYyM01UsIFSUoCioof7nkRE5oYNgEJ4u3rj3KxzcLBxQI9NPXDs8rF6jefhASQmaq8u6NEDOHrUsNdFRETU+T0TEoCAAOCJJ/53UyT6n/pkSzVjtuIwW/liA6Agdo3tsGvsLrw16C08u/NZLD22FGXlZXUer1kzYNs2YOVKYPRo7c2JymoZbtSoUUa/T2IiEBio3eq4Z08gKwuYPh0YNEi74VF53T/VqJd/X/43+mzug5NXTkpTwH3qki0ZhtmKw2zli4sAG9AiQGMkqZPwwp4X8IjdI/js+c/g0tylXuNdvAiMGwc8+iiwYwfQurX+81fyr2DNqTXYfWk3HG0c0ca2DVxtXeHa3PV/v7d1RZvmbdDGtg2aWjXFmTPA228DP/wAvPqq9pLGli3/N+aZM9q1CG5uwKefAm3a1OtLMMrW81vx2sHXMOGJCdj9625Ej4nGmC5jHl4BREQ14EZA9EBeLl74acZPeOWbV+C1yQufPf8Z/B7zq/N43btrp+RnzND+lL5rl3ZDopS/UhBxMgKf//w5RnYeiR1jdqC0vBRZhVnILMxEZmEmfvjzB93vs4qycLf8LhrddUBZXhu07+2K4ZNdgVau+Cy1DVyvaxuFvm37om9fK5w/D8yerd3nYNs2YPhw02VUnbLyMiw4ugAfn/8YB4IOYEjHIRjtMRqT9k7CysKVeLXvq2ILICJ6SNgAKJhtY1tEj4nG1vNbMXrXaLzu+zreHvw2GlnU7Y/dzk77jX/jRmDYtJ/w+LQV+F31DYK7BSPp70no3LIzEhIS4OvrW+3rf/wReHtpOeITbuKF6ZkInJaFWxb/bQwKs/Dbzd+QWZiJ9Nx0tLVri+gx0ejauiuio7WXJU6cCLz0EhARATRuXJ9kqld4pxCT9k3S3sdheiIeb/E4AGBk55E4OuUoRuwcgYz8DKzwWwEL1cP/9KymbKl+mK04zFa+uAZA4VQqFV7u9TISpidgX/I+DN0+FNcKrtVprIqKCsRf/h5f2g6D6m+DcOXn9njqXCpWD/gYnVt2BgAkJSVVed1PP2lvazx4MPCEpwUuX2qFbSu9MME7AC/1fAmLBy7GB89+gC8nfInE6Ym4GnoVw92Hw2eLD1adXIWy8jJMnqzd/vjUKcDHR3ulgCn9mfcnntz6JIpLi5HwcoLum/89vo/44tTLp/DFpS8w5cspKCkrMW0BBqguWzINZitOfbMtLi2u8/9ZVDM2AGaia+uu+HHGj+jo0BE9onrgUOohg19bXlGOr1K+gu/Hvhi3exz6P9IfGaF/4nLUe2hW9gh69dJ+Xg8As2bN0r3u7FntN/5Bg7RXFaSnA6tWVV0/cD9rS2ssG7oM3035Dh+f/xiDtg1Cak4q3N2BEye0N0Hq0wfYsgWo4x2W9ZzOOI2+W/riqfZP4WDwQTg2caz2vE4tOuH0y6eR8lcKhn82HPma/Pq/uREqZ0umxWzFqU+2R/84iq4bu+LxDY9j5887TVgVAWwAzEoz62bYNnob3h32LsZ/MR4Lji5AaVnpA88vLSvF9qTt6LaxG2Z/OxsveL6AP1//E0uHLEXLpi3h6Ah89RXw2mvAkCHAhg3ab8jnzgEjRwIDBwKdOwN//KFdzV/bN/77+T7ii/OzzqNXm17oGdUTG3/cCCurCkREAPv2Af/4BzBhApCXV/dMPrv4Gfyi/bB4wGJ8MPwDWFla1Xi+c3NnHJt2DFaWVhi4bSAyC2veJKGiQntVw82bda+RyNzcvH0T076ahudjnkeobyi+GP8FXv32VYQcDKnx/ywyDq8CUOhVALVJzk7GC3te0F062M6+ne6526W3sfX8Vrx76l1YWVohrH8YpnhNQeNGD/7g/eRJ7TdjOzvg8mXglVeAN94AXOp38YHOd398h7/F/g1dWnXBxyM/xiN2j+DGDeBvfwN++QXYuRN48knDxyuvKMeS+CXYcGYDYsbFIMA9wKh6SstKMevALBz94ygOvXgInq08UVYG/P47cP48cOGC9tf588Bff2kbAUdHoFMn4PHHtb8q/95M/xoS6amoqMCuX3Yh5FAIfB/xxQfDP9D935SWk4axu8fCtrEtdo/bjTb/396dx0Vd7Y8ffzEgCgy7gAqM7IJbKmka6C9xr7wGplam9k2z5VpZluXj1u3XbXHNzJIroKlUdtPCNAtcyq8LkWZXJEVZLUaTRbYBZJ/5/nFidJR1gBA5z8fj85hhGM7nzPHjnPfnfM7nfaz/wtuCbkEyFbBktACnAI4vOE7/nv0ZEjGEb1K+oaiiiHePvovHOg82/XcTK8ev5Pzfz/NE4BONdv4gOt9Tp8DNbRmZmfDee23X+QOM8xrHr0//Sh/rPgz69yA+TfoUJycde/fCiy/CxIliJcOm8hSACHBmfTmL7b9uJ2F+Qos7f4Dqym4sdNnMoNrHGPpREP2nHMXaWtwhsW6dGJUIDYU9e6CkBIqL4cABWLxYdPxpaeJ9EyaAra1oq9GjxSTHFSvEEs9JSXD16rV9Llu2rMX1vJ1pNLBvH2RktL4s2baGCsoLOJh5kIqailaX1dy2zSrO4v7P72fxvsVsuHcDux/abXBi4u3gzY/zf8TDzoPAyMBbJj9HZyZHAOSpF9t/3c5Te59Cq9MyrPcwlgUvY7LPZEwaWz6wAdnZ2fRqy56/HntS9vDEN08QrApm430bcbJyIjFR3CXg7CzyFKhU9f/tJc0lpv1nGpbdLImZFUNPy571v/E6V67cfFafkiLO6IcOBZM7Izli8SLLR27l2ZAHMWvhTRb5+SIgSEuD1FTD56Wl4OYmRgk8PLKZMKEXwcHg7t50ubcbnU6M9sTGiu3YMdE2ly6J9pgwQQSCISFgZ9eysv+K4/ZWV1heyO6U3ew4u4ODmQext7CnVlvL40Mf56k7n8LL3suocptq21ptLR+d+IjXDr3GzP4zWT1xNQ4WDg2+X6fTseHnDbxy8BVWjl/J34f/3ajvqs6uLUYAZAAgAwAAfiv6jbyyPIa7Du/oqjRLXlkeT3/7NEezjhJ5fyTT/KdRVibOsL/6CqKiYPp0w785nvULD+z4G6OcJ7LYZyNlxd0pLKTRLTcXsrOvpUQeOlQ8DhkCrq7Xlljem7qXh796mLfHvs3zI59vk8+o00FOzrVgIClJXGpJTIQ+fSA4WIy8BAfDwIFgatomu72laDQiDXVsLMTFQUEBjBsnMkdOngyeniJIOnIE9u8XoywpKWKS6MSJIii46y7o1vjUji6rqKKIPSl72HF2B/sz9jPIZRAz+89kxoAZeNp5cvj3w4T/HM7ulN2M8xzHM8OfYYrPFEwV1w622loxylVUJEa6iouvPddooH9/MbpVX2D8a86vLPhmAflX84mcGkmIZ0iz6x6fFc+MnTMY5zWOiPsjsOxm2RZN0mnIAMBIMgC4Peh0Orb/up1FsYuY1m8aH0z+ANsetuzcCQsXirPmykrRkec5fUnF5Mfgf9+g+39fwsHeBHt7mtx69hRfYLa2Tdfn+MXj3P/5/Tx2x2OsnLCyTXIF6HQ6LhRdID4rnouai/g5+tHXKoArqT4c/9Gc+HhISACFAkaNuhYUjBghUjl3NnVn+d99Jzr9+Hjx7zhlithGj246B8TFiyJoqAsIKivFJNWJE8Xm43MtcLvVVNdWY6Ywa9czWk2lRt/p78vYxwCnAcwcMJMZ/Wfg7eANiA48Jgby8sTzP0ouc8pkE2k2EehqzbBLfwrTpPmUZDtRUiLKVSjE/xNbWzECY2sLSqW4DbimRkwMDg0VQRlmFbx95G3WJqzl+bue55//759YdLNo8WfJLs1m5s6ZaCo1xMyKMXqUojOSAYCRZADQfvbt28ekSZP+0n1e1FxkwZ4FJOcls2XaFsZ5jUOthsOHwcZGx17Nu3z2+wo+CvmUh4dOo0eP9qtLWn4aUz6bwnDX4WydtrXJuRM3qtHWkJidSHxWPMfUx4jPiifvah6BvQMxv2BOiaqElCspVNVW4e3gTUDPAPwc/LEqD0CT6U/mCX9OHLElN1eMVtQFBEFBbTsnoy1df5YfGys6nOvP8j08jC9bq4XTp68FA0ePipTSdaMDISE6qsyzOfbDMWZMm9Fmn6m5dDodyXnJxKXHEZcex5Hfj9DNtBu+jr74Ofrh6yAe6547WjoatR9NpYZvUr5hR/IO4tLjCOgZoO/0r895kZ0t5qaEh0NAgEjDbdCh29SQYbaHQ2XhnCs9xgS3B1kw+BlCfEdhbW1Sb2D13Xf7sLWdREwM7NoF2d0PYxa6ECdbG7ZNjyLYZ4ixzQeIoOnlAy8TfTqaT8M+5V7fdk4XeouQAYCRZADQfr744gtmzZr1l+9Xp9MR8UsELx942eAMfMGeBRz5/Qh7Ht7DkF6t+6JprtyyXO7bfh9KcyW7Zu3CrkfDF6Q1lRp+uviTvsM/fvE4Zgoz7na/m2BVMEHuQQx3HY5lN0t922p1WrKKszh/5Tzn8s6JxyviMe9qHr2VvfFUBmBZ7k+FOoBLiQFcOOmPl1Mfgu42wd1djGxcvzk5iUcrq7Y/O66tFcPBN15eycwUw/rGnOW3hE6nI6csh7T8NM5kp/G/SWmc+j0ddVkaFZbpYF4Gv4LzHf0YbB/EGI8gpg4J4g5Xv3Y5Ey8oK+bzEwfZczaO4wVxlNbmo7wyloozk6lMnkBv1xrGTk/D485UcqrTSM1PJTU/lZyyHBwsHPRBgf7R0RdfB1+su1sb7KeksoS9qXvZkbyD2LRY/Bz99J1+XeKuOhcuiFt1t2wRi3ItWwZ339345zh/5TwbT25ka+JWPOw8eGb4Mzwy6BGU5kqD99Udt0UVRbx8YCmfnd7O6Oq3uLTrWdJSzBg/HsLCxAiBk5Px7br91+0s/GYhS4OW8tqY1zokW+dfSQYARpIBwO0royCDeV/PI7csV5/QZ/dDu1u9GFJLlVaVMuvLWWQVZxE7OxY3GzdAjFYcyzqm7/CTcpJQ2aoIcg/Sd/gDnAcY/eWVfzVfHxCcyzvH+XwRJPxW9Bs9FErsa/vRraIPJldd0GpcqCp05mqeCyXZzuhKXDCvdqGn0h6nniY3BQnXbyA68YKC+udOFBRqyb9aQGFVDiW6XLDKwUSZS4+eOXSzy0VhnYOZVQmujrb4uNnh1tMOux6NbzbdbRpsF51OR25ZLmkFaaTlp5FekC6eF4jnpVWluNm44esgOksfBx98HX2xq/Ul/Wcv/nvmKqfyEsiojiffMh5tr58xqbHCruRu+iqCuMM+iCDPO+nn3QMvLzEHQ9HEP1FVFaSnw5mzWg6dSyQ+N45MkzjK7BOgwA/HgskM6D6ZYNVoBvfvQUCAmGty4ABERMChQ3D//fDkk6JTLq3WkJYvPlNdUFD3vKiiiF7KXvrAoLCikO/SvsPb3lvf6Qc4BdxUx7NnxV0nO3aIOTOvvirW/WiJsqoyPj/zORt+3kBmYSbz7pjH03c+rd+fTqcj5lwMi2IXMdhlMBvv24invScg5rfs2iW2n38WI1ahoWJraCJvY5Jykgj7IowApwA+Cf2k0eC7vVXXVpNVnEVmYea1rUg82na35Yd5P7SqfBkAGEkGALe3Wm0t7//0PhkFGaydtNaoa4ttoUZbw1N7n2Jfxj7G9B3DsaxjXNRcZEivIQYdvquNa7vXpby6nNT8VFLyU8guzSanNIfcslxyyq495pTmUF5TjqmJGbZmzihxoUetM90qXTC56oy2xIWqAhfK8pwxUWjp7iA6cxPrHHQWuVR3z6HSLJcycijR5qGlFkszJT0tnOmldKG3jTMuVi44WznjonTB2twaTaWGooqia1tlkeHPf25anRYTTLDpbmMQFCjNlVwuvUxafholVSX0se6j7+Trzox9HHzwdvBu9iQxnQ7+yKki7vR/OZQez6n8eDJr4qk0KcL8SiCV6UGY/RGEyiQIP1cnvLxEx+3oKDr85GT4NTOPDA6g8I3DxHcfJmYV+JmNZ4zrZGYMncTowaom7xa5cEFMZv34Y7C0FAtx/c//3HwpR6fTkV+efy0oyE+ju1l3pgdMZ4DzgHrLPn4cli8Xt1HOnStydvj4NKt5Gmk3HccvHSf853B2nN3B3e53M3/ofL489yVHfz/KusnrmD1odoOjKpcuwe7dYu7B4cNiAbCwMBEMBPwZu2i1UFEhbo+tbysvh7ySIj68NIc/qs4x2ywG24rBlJeLeQjBweLSj7V1vVVo8ectKC8w7OCv6+SzirMwNTHFw84DL3svg83XwZdBLoNatX8ZABhJBgDtp6Kigh7teZG9k9HpdIT/HE7e1TyCVcHc5XrXTUO1zfVXtG1pVakICEpzrgUH9QQLpiam+o7c2fLPRyvDDt7ZyrlNZmbrdDpKq0rrDQw0lRp6KXvh6+iLt703VubGfRE21bY6nY6Mwgzis+I58ns8Ry/8SHpxMk6mPjhXBGGeE0TNFU8UnofJt4/jkvYX+jsMYWrAZKb4Tmak28gms0w2pLpa5JOIiBAd49/+JkYFQkKaHoUw/Azw/fei4z9xQpTx4otiNKOtXbl6hY9PfcyWxC0M7TmUD+7/ACer5o/v5+fD3r1iZGDfPnFJqLJSdP51TEzAwkIERzduPSy0XPR6m3SX1QQXRjCIR6itFaMq6ekiPfl994kRloYCH61OS15ZHmqNmqziLNTF4vG34t/0nb2mUoOTpdNNHXzd5mrtanDHRFvq9AHA9u3biYmJobS0lMDAQJYsWYKDQ/33fxYUFLB27VpOnjyJlZUVoaGhPProo0aVJwOA9vPiiy+ydu3ajq7GbUm2bfsxpm0LywtJuJhAfFY88ep4MgszGd13NJO9JzPReyIuSpc2r2dGhhgV2LJFnMXWjQo0lmZbqxVn1suXi79/7jmRvruBr9o219rjtrRUdNo3dvLduzc9XyU2LZbZMbOZM3gOayaKzKaZmfDtt/B1rIYjp9W4+GYRMFKNi18WJrZqLpaKzl6tUVNVW4WTpRPutu6obFW427gbnNF72nkaHdC3VqcOAGJjY1m/fj3Lli2jT58+fPTRR+h0Oj744IN63//88+Le6meffZbLly+zfPlyFi1axL1/LhDfkvJkANB+vvnmG6ZOndrR1bgtybZtP52tbauqRKceESHubHjgAXFGf88910YFqqvh88/FNf7iYliyRNweq1Q2WnSb6+i2zSzMJOyLMMwUZrgoXfRn88WVxVh1s8JeoUJXpKLgN3e0he4MUqkICXQnNETFHZ5uHXYJsSltEQAYtzB8G9i1axfTp09nzJgxACxdupTZs2eTnp6Ozw1jMhkZGSQlJREdHY27uzs+Pj6kpaURExOjDwBaUp7Ufg4dOtSpvkg7E9m27aezta25OcyYIba0NDEqMGuWuF1v4UIxNL5mjUiA9MorMGdO295Z0RId3bZe9l78OP9HNp7ciIWZhcHZvF0PO/2cBK1WZPn89lvY+zGs+btIKFV3qWDIkJbdIVNTIxIkaTQ3P/boIVZK7WgdEgBUVVWRkZFhsExknz596NWrF8nJyTd12OfPn8fJyQn36/KfDhs2jM8++4zKykpMTExaVJ4kSdLtwtdXLLP91ltidc6ICNHRrFwJDz54e2aIbCnLbpa8OOrFRt+jUEBgoNj++U+REyE2VsxFWLVKLNh1770i7XR9HfuNr9XNVzAxEZdrrK1FGdbWInNnlw0ANBoNWq0We3vDddft7Owoqmdt18LCQuxuSO5tZ2eHVquluLgYhULRovJ0fy4ir9FoWvtRpBucPXtWtms7kW3bfm6Xtq3LpVCnrKzj6lKns7atpaW4NXL6dHHJJT5eJJRKSbnWmffpIy6p2NiIR2vra491zxvKrdHaJqlr07r+zBgdEgC0psJtUV55eTmAwYiC1HZsm5M3VzKKbNv2I9u2/ci2bT/l5eUojZzY0SEBgK2tLQqFgsLCQoPXi4qKbjrTB7C3t7/pTL6oqAiFQoGtrS0mJiYtKs/R0ZEdO3ZgYWHRJVeRkiRJkjo3nU5HeXk5jo7GpYeGDgoAzM3N8fb2JjExkcDAQAAuX75MdnY2/fv3v+n9/v7+5OXlcfHiRdzcREa1U6dO4enpSfc/Z7a0pDyFQoFTa3JOSpIkSVIHM/bMv47pY4899v/bpCYt3bGpKdu2bUOlUlFdXc0HH3yAs7Mzs2fP5ty5cyxZsoTg4GCsrKxwcHDg1KlTJCQk4OPjQ3JyMpGRkcybNw9fX98my5MkSZIkyVCH3QZ47733UlhYyLp16/SJe1566SUAKisrUavV1NbW6t//xhtv8N5777Fo0SIsLS15+OGH9bcANlWeJEmSJEmGumQqYEmSJEnq6jpsBKCjtCT9sNQ8W7duZdu2bQavBQUF8fbbb3dQjTqvI0eO8PXXX5OamkpZWRkHDx7E9LobudVqNWvXriU5ORl7e3vmzp1rMBImNaypth07duxNfxMVFSXziDTh008/5ciRI6jVaiwtLRkxYgRPPvmkwQRsedwapzlt25rjtksFALGxsXzyyScG6YLffPPNBtMPS83n7+/PO++8o//Z3Ny8A2vTeVVWVjJs2DACAwPZtGmTwe9qampYtmwZPj4+bNy4keTkZNauXYuLi4t+8qvUsMbats4bb7zB4OvWw5W3rzXtzJkzzJgxg379+lFWVsb69ev517/+pc//L49b4zXVtnWMPW67VAAg0wW3HzMzMzmS0gYmTJgAQGJi4k2/O378OLm5uURGRmJpaYmnpyenT59m165d8ou0GRpr2zrW1tbyOG6hFStWGPy8aNEiFi1aRGlpKUqlUh63rdBU29Yx9rhtwWKSnVtd+uGhQ4fqX7s+XbDUOhkZGYSFhTFnzhzWrVtHSUlJR1fptnP+/Hn8/f2xtLy2xO6wYcM4d+5cB9bq9rJixQpCQ0N57rnnSEhI6OjqdErFxcWYm5tjYSEW0ZHHbdu5sW3rGHvcdpkRgJamH5aar3///ixbtgxXV1eys7OJioritddeY926dTLRUhtqKCW2PH7bxvz58xk2bBimpqYcO3aMf/zjH6xevVqepbZAVVUV0dHRTJo0ST+/Qh63baO+toXWHbddJgBo6/TD0jUjRozQP/fy8qJv3748+uijpKam0q9fvw6smSQ136OPPqp/3q9fP3Jycvjyyy9lANBMtbW1vPvuuwA8/fTTHVyb20tjbdua47bLXAJoafphyXiurq4olUouX77c0VW5rTSUElsev+3Dz89PHsPNpNVqWblyJVlZWaxatcpgiFoet63TWNvWpyXHbZcJAK5PP1ynsXTBkvFycnIoLS2lV69eHV2V24q/vz8pKSn6xaxApMQOCAjowFrdvjIyMuQx3Aw6nY7Vq1eTnJzMmjVrsLGxMfi9PG6N11Tb1qclx22XuQQA8MADD/DRRx/h5+dH7969CQ8PZ/DgwfIOgFbauHEjQUFBODk5cfnyZTZu3MiAAQPw8/Pr6Kp1OhqNhtzcXC5dugRAeno6pqamuLq6MmLECHr27MnKlSuZN28e586d44cffrhpprBUv8baNjExkaKiIgICAjA1NeXo0aPs379fP+wqNWzt2rUkJCSwfPlyAAoKCgAx6mpqaiqP21Zoqm0TEhJaddx2uUyAn332mUEioJdeekne9tNKb775JklJSWg0GhwdHRk+fDjz58+XQ3xGiIuLY+XKlTe9/v777zNkyBCysrL0CVUcHByYM2cO9913XwfUtPNprG2rqqqIiIjgjz/+QKFQoFKpmD17NsHBwR1Q086lvkQ0AJ9//rn+TFQet8Zpqm1PnDjRquO2ywUAkiRJkiR1oTkAkiRJkiRdIwMASZIkSeqCZAAgSZIkSV2QDAAkSZIkqQuSAYAkSZIkdUEyAJAkSZKkLkgGAJIkSZLUBckAQJIkSZK6IBkASJLUKrGxscycOZOQkBDi4uI6ujr1Gjt2LL/88ktHV0OSbildai0ASZLaVnV1NevWreOpp55izJgxKJXKm97TUAre4cOHs2rVqr+impIk1UMGAJIkGS0/P5+qqipGjhyJo6Njg+9zdHQkMjLS4LVu3bq1d/UkSWqEDAAk6Ra0ePFi/P39KSsr4/vvv8fGxoaFCxcSEhICiLPqzZs3s3PnTv3fbN26lV9++YUPP/zQoIzS0lJ++OEHbGxsWLx4Md7e3qxYsYLknefeAwAABYdJREFU5GS8vb157bXXGl0+dN++fURHR5OXl4ebmxtPPvkkd911F4mJibzwwgsAPPLII4DhAjDXMzExaXTRrbFjx7JkyRL279/P+fPn8fT05JVXXsHLy0v/nv/85z/ExMRQVFSEj48Pzz77rMGSsidPnmTz5s1kZGSgVCoZPXq0vn4AeXl5LFmyhLNnz6JSqXjllVfw9vYGIDU1lQ8//JD09HTMzMzw8vLinXfeqXdEQ5JuF3IOgCTdovbu3YtKpSIqKorJkyezcuVKCgsLW1yGh4cHkZGRjBw5kuXLl7N69WoefPBBIiIiAAgPD2/w78+cOcOqVasICwtj06ZNBAcH8/rrr5Odnc2AAQPYsGEDAP/+97/56quvcHJyMvrzbtmyhbCwMCIjI+nduzevv/46tbW1ABw8eJBt27bxxBNPEBUVhZeXF6+++iplZWUA/PbbbyxbtozAwECioqJYsWIFffv2NSg/Ojqa0NBQoqKi9MvT1nn33XcZOHAgmzdvZv369YwfP97ozyFJnYUMACTpFjVw4EBmzJiBq6src+bMQaFQcP78+RaX8eCDD+Lm5sbcuXPRaDQEBgYyatQoVCoVYWFhnD59usG/j4mJYfTo0UyfPh2VSsXjjz+Oj48PX3/9Nd26dcPW1hYAOzs7HBwcMDU1rbec/Px8pkyZYrBFR0cbvGfSpEncc889eHh48NJLL1FQUMCJEyf09Zg2bRoTJkygb9++vPDCC3Tv3p39+/cDYuThzjvvZMGCBfTt2xc/Pz/CwsIMyp86dSrBwcG4u7sze/Zs0tLSKC8vByA3N5dRo0bRp08fPD09mTp1qjz7l2578hKAJN2iPD099c9NTU2xtbVt8QjA9WXY29sD4OHhYfCaRqOhtra23s5brVYzYcIEg9cGDBiAWq1uUT3s7e1Zv369wWvW1tYGP/v7++ufK5VK3N3dUavVjBo1CrVazUMPPaT/vampKf369dPX48KFC4wbN67ROlx/OaHuckRhYSEWFhaEhoby8ssvM3z4cAIDAwkJCdEHN5J0u5IBgCTdoszMbv7vqdPpAHFN/UY1NTWNllH3N/W91pC6/bWWQqHA1dW10fc0VZfWqu9z132+J554gvHjx5OQkMCBAwfYunUrGzZswM3NrV3rJEkdSV4CkKROyM7OjuLiYoNO/8KFC22+H5VKRXJyssFrZ8+exd3dvc33df3ljbKyMtRqtX4/7u7uBvWora0lJSUFlUoFiJGOxMTEVu3f09OTRx55hPDwcOzt7Tl69GirypOkW50MACSpE/L390ehUBAdHc2lS5f46quvGr2Wb6ywsDCOHj3Krl27UKvVfPzxx6Snp/PAAw+0qBydTkdBQYHBVlxcbPCeffv2cfjwYX7//XfWrFmDg4MDI0aMAGD69Ons3r2bgwcPkpWVxfvvv09lZaX+8sTDDz/MyZMn2bRpE1lZWaSnp7Nr165m1a2yspL169eTlJREdnY2P/30E7m5ue0S5EjSrUReApCkTsjW1palS5cSFRXFzp07GTt2LNOmTSMpKalN9zNw4ECWLl1KdHQ04eHhuLu789ZbbzV622B98vPzmT59usFr7u7uBhMB582bx86dO0lNTcXDw4M333xTPy9h3Lhx5OXlERERQXFxMT4+PqxYsQIrKytAzGt455132LRpEzt27ECpVHLPPfc0q24KhYKioiLeeustiouL6dmzJ3PnziU4OLhFn1GSOhuTQ4cOtc1FPkmSJCONHTuWNWvWEBgY2NFVkaQuQ14CkCRJkqQuSAYAkiRJktQFyTkAkiR1uEOHDnV0FSSpy5EjAJIkSZLUBckAQJIkSZK6IBkASJIkSVIXJAMASZIkSeqCZAAgSZIkSV2QDAAkSZIkqQv6P5nPHByXF4LDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f834b0160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "plt.savefig('8th_attempt_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
